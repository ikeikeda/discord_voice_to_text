import logging
import asyncio
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import discord
from pydub import AudioSegment
import io
import tempfile
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class SpeakerSegment:
    """è©±è€…ã”ã¨ã®ç™ºè¨€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ"""
    user_id: int
    user_name: str
    start_time: float
    end_time: float
    text: str
    confidence: float = 1.0


@dataclass
class SpeechStatistics:
    """ç™ºè¨€çµ±è¨ˆæƒ…å ±"""
    user_id: int
    user_name: str
    total_duration: float  # ç·ç™ºè¨€æ™‚é–“ï¼ˆç§’ï¼‰
    segment_count: int     # ç™ºè¨€å›æ•°
    word_count: int        # å˜èªæ•°
    avg_segment_length: float  # å¹³å‡ç™ºè¨€æ™‚é–“
    participation_ratio: float  # å‚åŠ ç‡ï¼ˆ%ï¼‰


class SpeakerAnalyzer:
    """è©±è€…è­˜åˆ¥ãƒ»åˆ†æã‚¯ãƒ©ã‚¹"""

    def __init__(self, output_dir: str = "recordings"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # è©±è€…è­˜åˆ¥ã®æœ‰åŠ¹/ç„¡åŠ¹è¨­å®š
        self.enable_speaker_identification = os.getenv("ENABLE_SPEAKER_IDENTIFICATION", "true").lower() == "true"
        self.enable_speaker_statistics = os.getenv("ENABLE_SPEAKER_STATISTICS", "true").lower() == "true"
        
        # æœ€å°ç™ºè¨€æ™‚é–“ï¼ˆç§’ï¼‰- ã“ã‚Œã‚ˆã‚ŠçŸ­ã„ç™ºè¨€ã¯ç„¡è¦–
        self.min_speech_duration = float(os.getenv("MIN_SPEECH_DURATION", "1.0"))
        
        # è©±è€…åˆ‡ã‚Šæ›¿ãˆæ¤œå‡ºã®é–¾å€¤ï¼ˆç§’ï¼‰
        self.speaker_change_threshold = float(os.getenv("SPEAKER_CHANGE_THRESHOLD", "0.5"))

    async def analyze_recording_with_speakers(
        self, 
        sink: discord.sinks.Sink, 
        participants: List[discord.Member],
        transcription: str
    ) -> Tuple[List[SpeakerSegment], List[SpeechStatistics]]:
        """éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è©±è€…è­˜åˆ¥ãƒ»çµ±è¨ˆåˆ†æã‚’å®Ÿè¡Œ"""
        try:
            if not self.enable_speaker_identification:
                # è©±è€…è­˜åˆ¥ç„¡åŠ¹æ™‚ã¯å…¨ä½“ã‚’1ã¤ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ‰±ã†
                return self._create_single_segment(transcription, participants), []
            
            logger.info("è©±è€…è­˜åˆ¥åˆ†æã‚’é–‹å§‹")
            
            # 1. å„å‚åŠ è€…ã®å€‹åˆ¥éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            speaker_audio_files = await self._extract_individual_audio(sink, participants)
            
            # 2. å„éŸ³å£°ã®æ´»å‹•åŒºé–“ã‚’æ¤œå‡º
            speaker_activities = await self._detect_speech_activities(speaker_audio_files)
            
            # 3. æ–‡å­—èµ·ã“ã—çµæœã‚’è©±è€…ã”ã¨ã«åˆ†å‰²
            speaker_segments = await self._assign_text_to_speakers(
                transcription, speaker_activities, participants
            )
            
            # 4. çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
            statistics = self._calculate_statistics(speaker_segments, participants)
            
            # 5. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            await self._cleanup_temp_files(speaker_audio_files)
            
            logger.info(f"è©±è€…è­˜åˆ¥å®Œäº†: {len(speaker_segments)} ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ, {len(statistics)} è©±è€…")
            return speaker_segments, statistics
            
        except Exception as e:
            logger.error(f"è©±è€…åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…¨ä½“ã‚’1ã¤ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦è¿”ã™
            return self._create_single_segment(transcription, participants), []

    async def _extract_individual_audio(
        self, 
        sink: discord.sinks.Sink, 
        participants: List[discord.Member]
    ) -> Dict[int, str]:
        """å„å‚åŠ è€…ã®å€‹åˆ¥éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠ½å‡º"""
        speaker_files = {}
        
        if not sink.audio_data:
            logger.warning("éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return speaker_files
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        for user_id, audio_data in sink.audio_data.items():
            try:
                # Discordã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—
                user = next((p for p in participants if p.id == user_id), None)
                if not user:
                    continue
                
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                temp_file = tempfile.NamedTemporaryFile(
                    suffix=f"_{user.display_name}_{timestamp}.wav", 
                    delete=False
                )
                
                # AudioSegmentã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
                audio = AudioSegment.from_file(io.BytesIO(audio_data.file.read()), format="wav")
                
                # ç„¡éŸ³éƒ¨åˆ†ãŒå¤šã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if len(audio) < self.min_speech_duration * 1000:  # mså¤‰æ›
                    temp_file.close()
                    os.unlink(temp_file.name)
                    continue
                
                audio.export(temp_file.name, format="wav")
                speaker_files[user_id] = temp_file.name
                
                logger.debug(f"å€‹åˆ¥éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {user.display_name} -> {temp_file.name}")
                
            except Exception as e:
                logger.error(f"å€‹åˆ¥éŸ³å£°æŠ½å‡ºã‚¨ãƒ©ãƒ¼ (user_id: {user_id}): {e}")
                continue
        
        return speaker_files

    async def _detect_speech_activities(
        self, 
        speaker_audio_files: Dict[int, str]
    ) -> Dict[int, List[Tuple[float, float]]]:
        """å„è©±è€…ã®ç™ºè¨€åŒºé–“ã‚’æ¤œå‡º"""
        activities = {}
        
        for user_id, audio_file in speaker_audio_files.items():
            try:
                # AudioSegmentã§éŸ³å£°ã‚’èª­ã¿è¾¼ã¿
                audio = AudioSegment.from_wav(audio_file)
                
                # éŸ³å£°æ´»å‹•åŒºé–“ã‚’æ¤œå‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
                activity_segments = self._detect_voice_activity(audio)
                activities[user_id] = activity_segments
                
            except Exception as e:
                logger.error(f"éŸ³å£°æ´»å‹•æ¤œå‡ºã‚¨ãƒ©ãƒ¼ (user_id: {user_id}): {e}")
                activities[user_id] = []
        
        return activities

    def _detect_voice_activity(self, audio: AudioSegment) -> List[Tuple[float, float]]:
        """éŸ³å£°æ´»å‹•åŒºé–“æ¤œå‡ºï¼ˆVAD: Voice Activity Detectionï¼‰"""
        # ç°¡æ˜“çš„ãªVADå®Ÿè£…
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚ˆã‚Šé«˜åº¦ãªVADã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆWebRTCVADç­‰ï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨
        
        silence_threshold = -40  # dBFS
        min_silence_duration = 500  # ms
        min_speech_duration = int(self.min_speech_duration * 1000)  # ms
        
        segments = []
        speech_start = None
        
        # 100msã”ã¨ã«ãƒã‚§ãƒƒã‚¯
        chunk_length = 100
        for i in range(0, len(audio), chunk_length):
            chunk = audio[i:i + chunk_length]
            
            if len(chunk) < chunk_length:
                break
            
            # éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
            db_level = chunk.dBFS
            
            if db_level > silence_threshold:
                # éŸ³å£°æ¤œå‡º
                if speech_start is None:
                    speech_start = i / 1000.0  # ç§’ã«å¤‰æ›
            else:
                # ç„¡éŸ³æ¤œå‡º
                if speech_start is not None:
                    speech_end = i / 1000.0
                    duration = (speech_end - speech_start) * 1000
                    
                    # æœ€å°ç™ºè¨€æ™‚é–“ä»¥ä¸Šã®å ´åˆã®ã¿è¨˜éŒ²
                    if duration >= min_speech_duration:
                        segments.append((speech_start, speech_end))
                    
                    speech_start = None
        
        # æœ€å¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†
        if speech_start is not None:
            speech_end = len(audio) / 1000.0
            duration = (speech_end - speech_start) * 1000
            if duration >= min_speech_duration:
                segments.append((speech_start, speech_end))
        
        return segments

    async def _assign_text_to_speakers(
        self,
        transcription: str,
        speaker_activities: Dict[int, List[Tuple[float, float]]],
        participants: List[discord.Member]
    ) -> List[SpeakerSegment]:
        """æ–‡å­—èµ·ã“ã—çµæœã‚’è©±è€…ã”ã¨ã«åˆ†å‰²"""
        segments = []
        
        if not speaker_activities:
            # è©±è€…æ´»å‹•ãŒæ¤œå‡ºã•ã‚Œãªã„å ´åˆã¯ã€å…¨ä½“ã‚’æœ€åˆã®å‚åŠ è€…ã¨ã—ã¦æ‰±ã†
            return self._create_single_segment(transcription, participants)
        
        # å…¨ã¦ã®ç™ºè¨€åŒºé–“ã‚’æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ
        all_activities = []
        for user_id, activities in speaker_activities.items():
            user = next((p for p in participants if p.id == user_id), None)
            if user:
                for start, end in activities:
                    all_activities.append((start, end, user_id, user.display_name))
        
        all_activities.sort(key=lambda x: x[0])  # é–‹å§‹æ™‚é–“ã§ã‚½ãƒ¼ãƒˆ
        
        # æ–‡å­—èµ·ã“ã—çµæœã‚’åŒºé–“æ•°ã§åˆ†å‰²ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        sentences = [s.strip() for s in transcription.split('ã€‚') if s.strip()]
        if not sentences:
            return segments
        
        # å„ç™ºè¨€åŒºé–“ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰²ã‚Šå½“ã¦
        segment_count = len(all_activities)
        text_per_segment = max(1, len(sentences) // max(1, segment_count))
        
        for i, (start, end, user_id, user_name) in enumerate(all_activities):
            # ã“ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«å¯¾å¿œã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            start_idx = i * text_per_segment
            end_idx = min((i + 1) * text_per_segment, len(sentences))
            
            if start_idx < len(sentences):
                segment_text = 'ã€‚'.join(sentences[start_idx:end_idx])
                if segment_text:
                    segments.append(SpeakerSegment(
                        user_id=user_id,
                        user_name=user_name,
                        start_time=start,
                        end_time=end,
                        text=segment_text + 'ã€‚' if not segment_text.endswith('ã€‚') else segment_text
                    ))
        
        return segments

    def _create_single_segment(
        self, 
        transcription: str, 
        participants: List[discord.Member]
    ) -> List[SpeakerSegment]:
        """è©±è€…è­˜åˆ¥ãªã—ã§å…¨ä½“ã‚’1ã¤ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦ä½œæˆ"""
        if not participants or not transcription.strip():
            return []
        
        # æœ€åˆã®å‚åŠ è€…ã‚’è©±è€…ã¨ã—ã¦è¨­å®š
        first_participant = participants[0]
        return [SpeakerSegment(
            user_id=first_participant.id,
            user_name=first_participant.display_name,
            start_time=0.0,
            end_time=0.0,  # æ™‚é–“æƒ…å ±ãªã—
            text=transcription.strip()
        )]

    def _calculate_statistics(
        self,
        segments: List[SpeakerSegment],
        participants: List[discord.Member]
    ) -> List[SpeechStatistics]:
        """ç™ºè¨€çµ±è¨ˆã‚’è¨ˆç®—"""
        if not self.enable_speaker_statistics:
            return []
        
        stats_dict = {}
        total_duration = sum(seg.end_time - seg.start_time for seg in segments if seg.end_time > 0)
        
        for segment in segments:
            user_id = segment.user_id
            if user_id not in stats_dict:
                stats_dict[user_id] = {
                    'user_name': segment.user_name,
                    'total_duration': 0.0,
                    'segment_count': 0,
                    'word_count': 0
                }
            
            stats = stats_dict[user_id]
            stats['total_duration'] += segment.end_time - segment.start_time
            stats['segment_count'] += 1
            stats['word_count'] += len(segment.text.replace('ã€‚', ' ').split())
        
        # çµ±è¨ˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        statistics = []
        for user_id, stats in stats_dict.items():
            avg_length = stats['total_duration'] / stats['segment_count'] if stats['segment_count'] > 0 else 0
            participation = (stats['total_duration'] / total_duration * 100) if total_duration > 0 else 0
            
            statistics.append(SpeechStatistics(
                user_id=user_id,
                user_name=stats['user_name'],
                total_duration=stats['total_duration'],
                segment_count=stats['segment_count'],
                word_count=stats['word_count'],
                avg_segment_length=avg_length,
                participation_ratio=participation
            ))
        
        return sorted(statistics, key=lambda x: x.total_duration, reverse=True)

    async def _cleanup_temp_files(self, speaker_audio_files: Dict[int, str]):
        """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        for user_id, file_path in speaker_audio_files.items():
            try:
                if os.path.exists(file_path):
                    os.unlink(file_path)
                    logger.debug(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {file_path}")
            except Exception as e:
                logger.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")

    def format_speaker_segments(self, segments: List[SpeakerSegment]) -> str:
        """è©±è€…è­˜åˆ¥çµæœã‚’æ•´å½¢ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›"""
        if not segments:
            return "è©±è€…è­˜åˆ¥çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        formatted_lines = []
        formatted_lines.append("=== è©±è€…åˆ¥æ–‡å­—èµ·ã“ã—çµæœ ===\n")
        
        for i, segment in enumerate(segments, 1):
            time_info = ""
            if segment.end_time > 0:
                time_info = f" [{segment.start_time:.1f}s - {segment.end_time:.1f}s]"
            
            formatted_lines.append(f"ã€{segment.user_name}ã€‘{time_info}")
            formatted_lines.append(f"{segment.text}\n")
        
        return "\n".join(formatted_lines)

    def format_statistics(self, statistics: List[SpeechStatistics]) -> str:
        """çµ±è¨ˆæƒ…å ±ã‚’æ•´å½¢ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›"""
        if not statistics:
            return "çµ±è¨ˆæƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        formatted_lines = []
        formatted_lines.append("=== ä¼šè­°çµ±è¨ˆæƒ…å ± ===\n")
        
        for stat in statistics:
            formatted_lines.append(f"ğŸ‘¤ {stat.user_name}")
            formatted_lines.append(f"  â€¢ ç™ºè¨€æ™‚é–“: {stat.total_duration:.1f}ç§’")
            formatted_lines.append(f"  â€¢ ç™ºè¨€å›æ•°: {stat.segment_count}å›")
            formatted_lines.append(f"  â€¢ å˜èªæ•°: {stat.word_count}èª")
            formatted_lines.append(f"  â€¢ å¹³å‡ç™ºè¨€æ™‚é–“: {stat.avg_segment_length:.1f}ç§’")
            formatted_lines.append(f"  â€¢ å‚åŠ ç‡: {stat.participation_ratio:.1f}%\n")
        
        return "\n".join(formatted_lines)